# Agent J: QA Reviewer
# Purpose: Ensure quality standards are met before publication

agent:
  name: "QA Reviewer"
  id: "qa_reviewer"
  version: "1.0"
  type: "governance"
  critical: true  # Failures block publication

model:
  primary: "llama3.2:70b"  # Use largest model for critical reviews
  fallback: "llama3.2:8b"
  temperature: 0.1  # Very low for consistency
  top_p: 0.85

system_prompt: |
  You are a quality assurance specialist for RKL (Resonant Knowledge Lab).
  Your role is to review weekly briefs before publication to ensure they meet
  high standards of quality, accuracy, and RKL governance principles.

  You must be thorough, objective, and constructive. Your reviews directly
  impact what gets published, so accuracy is critical.

  Review Principles:
  - Quality over speed
  - Be specific in feedback
  - Flag serious issues as failures
  - Suggest concrete improvements
  - Maintain RKL standards

quality_rubric:
  categories:
    content_quality:
      weight: 0.30
      checks:
        - name: "technical_accuracy"
          description: "Summaries match source articles"
          score_range: [0, 10]
        - name: "readability"
          description: "Appropriate for target audience"
          score_range: [0, 10]
        - name: "completeness"
          description: "All required sections present"
          score_range: [0, 10]

    rkl_compliance:
      weight: 0.25
      checks:
        - name: "terminology_correct"
          description: "Type I/II/III, CARE used correctly"
          score_range: [0, 10]
        - name: "attribution_complete"
          description: "Provenance and sources cited"
          score_range: [0, 10]
        - name: "type3_explained"
          description: "Type III nature mentioned"
          score_range: [0, 10]

    technical_quality:
      weight: 0.20
      checks:
        - name: "word_limits_met"
          description: "Summaries within 80-word limit"
          score_range: [0, 10]
          strict: true  # Must pass
        - name: "formatting_correct"
          description: "Markdown and Hugo front-matter valid"
          score_range: [0, 10]
        - name: "links_valid"
          description: "All URLs work"
          score_range: [0, 10]

    organizational_value:
      weight: 0.15
      checks:
        - name: "implications_clear"
          description: "Clear what orgs should do"
          score_range: [0, 10]
        - name: "recommendations_actionable"
          description: "Concrete, specific actions"
          score_range: [0, 10]

    writing_quality:
      weight: 0.10
      checks:
        - name: "grammar_correct"
          description: "No grammatical errors"
          score_range: [0, 10]
        - name: "style_consistent"
          description: "Maintains professional tone"
          score_range: [0, 10]

thresholds:
  pass_score: 7.0  # Overall score must be >= 7.0
  critical_checks:  # These must individually pass
    - "word_limits_met"
    - "formatting_correct"
    - "attribution_complete"

  failure_actions:
    score_below_7: "return_for_revision"
    score_below_5: "escalate_to_human"
    critical_check_failed: "block_publication"

max_iterations: 3  # Allow up to 3 revision cycles
escalate_after_iterations: 3

prompts:
  review_brief:
    template: |
      Review this Secure Reasoning Brief for quality and compliance.
      Score each category 0-10 and provide specific feedback.

      Brief content:
      {brief_content}

      Review Structure:
      1. Overall Assessment (score 0-10)
      2. Category Scores (content_quality, rkl_compliance, technical_quality, etc.)
      3. Specific Issues Found (list with severity: critical/major/minor)
      4. Recommendations for Improvement
      5. Decision: PASS / REVISE / FAIL

      Be thorough but constructive.

      Review:

    parameters:
      temperature: 0.1
      max_tokens: 1000

  check_word_counts:
    template: |
      Count the words in each technical summary section.
      Summaries must be 60-80 words.

      Brief content:
      {brief_content}

      For each article summary, report:
      - Article title
      - Word count
      - Status: PASS (60-80) / WARN (50-90) / FAIL (<50 or >90)

      Word count check:

    parameters:
      temperature: 0.0
      max_tokens: 500

  verify_rkl_terminology:
    template: |
      Check if this brief correctly uses RKL terminology:
      - Type I / Type II / Type III secure reasoning
      - CARE Principles (Collective Benefit, Authority to Control, Responsibility, Ethics)
      - Secure reasoning
      - Governance metadata
      - Provenance

      Brief content:
      {brief_content}

      Report:
      - Terms used correctly: [list]
      - Terms used incorrectly: [list with corrections]
      - Missing required terms: [list]
      - Overall RKL compliance: PASS / FAIL

      Terminology check:

    parameters:
      temperature: 0.0
      max_tokens: 300

feedback_style: "constructive"  # constructive / strict / minimal

feedback_template: |
  QA Review - {decision}
  Overall Score: {overall_score}/10

  Category Scores:
  {category_scores}

  Issues Found:
  {issues}

  Recommendations:
  {recommendations}

  {decision_explanation}

output:
  format: "json"
  schema:
    decision: "enum[PASS, REVISE, FAIL]"
    overall_score: "float"
    category_scores: "dict"
    issues: "list[dict]"
    recommendations: "list[string]"
    iteration: "int"

  save_to:
    - "telemetry/quality/scores.jsonl"
    - "audit/compliance/qa_reports/{date}_{brief_id}.json"

governance:
  critical_agent: true
  blocks_publication: true
  requires_audit: true

  audit_captures:
    - "full_brief_content"
    - "all_scores"
    - "decision_reasoning"
    - "issues_found"

performance:
  timeout_seconds: 300  # Longer for thorough review
  retry_on_failure: 1  # Limited retries for QA

  monitoring:
    track_review_time: true
    track_pass_rate: true
    track_revision_rounds: true
    alert_on_high_failure_rate: 0.30  # Alert if >30% need revision

telemetry:
  log_level: "INFO"
  log_file: "data/logs/agent_traces/qa_reviewer/{date}.log"
  metrics_file: "telemetry/quality/scores.jsonl"

  capture:
    - "review_duration"
    - "overall_score"
    - "pass_fail_decision"
    - "issues_count"
    - "iteration_number"

human_escalation:
  enabled: true
  conditions:
    - "score < 5.0"
    - "iterations >= 3"
    - "critical_check_failed"

  notification:
    method: "log"  # Future: email, slack
    message: "QA Review requires human intervention: {reason}"

version: "1.0"
last_updated: "2025-11-11"
